# ğŸ¤ DSP-Speech-Command-Recognition

> A **Distance-Based Speech Recognition System** using classical Digital Signal Processing (DSP) techniques â€” no deep learning required.

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/Platform-Local%20%7C%20Colab%20%7C%20Kaggle-orange.svg)](#-quick-start)

---

## ğŸ“‹ Overview

This project implements a complete speech recognition pipeline for classifying **8 spoken commands** using traditional DSP methods. It demonstrates fundamental signal processing concepts without relying on neural networks or deep learning frameworks.

### ğŸ¯ Supported Commands

| | | | |
|:---:|:---:|:---:|:---:|
| `down` | `go` | `left` | `no` |
| `right` | `stop` | `up` | `yes` |

---

## âœ¨ Features

- **ğŸ”§ Complete DSP Pipeline** â€” From raw audio to classification
- **ğŸ“Š No Deep Learning** â€” Pure signal processing approach
- **ğŸŒ Cross-Platform** â€” Runs on Local, Google Colab, and Kaggle
- **ğŸ’¾ Smart Caching** â€” Preprocessed data saved for fast reloading
- **ğŸ“ˆ Visualizations** â€” Waveforms, spectrograms, and processing steps
- **ğŸ§¹ Clean Code** â€” Follows SOLID, DRY, and KISS principles

---

## ğŸ—ï¸ Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SPEECH RECOGNITION PIPELINE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Audio   â”‚â”€â”€â”€â–¶â”‚ Preprocessing â”‚â”€â”€â”€â–¶â”‚ Framing â”‚â”€â”€â”€â–¶â”‚   Features    â”‚  â”‚
â”‚  â”‚  Input   â”‚    â”‚              â”‚    â”‚         â”‚    â”‚  (Coming Soon) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                â”‚                  â”‚                 â”‚          â”‚
â”‚       â–¼                â–¼                  â–¼                 â–¼          â”‚
â”‚   .wav files     â€¢ DC removal       â€¢ 25ms frames     â€¢ MFCC          â”‚
â”‚   16kHz mono     â€¢ Pre-emphasis     â€¢ 10ms hop        â€¢ Energy        â”‚
â”‚   1 second       â€¢ Normalization    â€¢ Hamming window  â€¢ ZCR           â”‚
â”‚                  â€¢ Deduplication                                       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Option 1: Google Colab
1. Upload the notebook to Colab
2. Run all cells

### Option 2: Local Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/DSP-Speech-Command-Recognition.git
cd DSP-Speech-Command-Recognition

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the notebook
jupyter notebook speech_recognition_pipeline.ipynb
```

### Option 3: Kaggle
1. Upload the notebook to Kaggle
2. Enable Internet access in notebook settings
3. Run all cells

---

## ğŸ“ Project Structure

```
DSP-Speech-Command-Recognition/
â”‚
â”œâ”€â”€ ğŸ““ speech_recognition_pipeline.ipynb  # Main notebook (self-contained)
â”œâ”€â”€ ğŸ“„ README.md                          # This file
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Python dependencies
â”œâ”€â”€ ğŸ“„ LICENSE                            # MIT License
â”‚
â”œâ”€â”€ ğŸ“‚ mini_speech_commands/              # Dataset (auto-downloaded)
â”‚   â””â”€â”€ ğŸ“‚ mini_speech_commands/
â”‚       â”œâ”€â”€ ğŸ“‚ down/
â”‚       â”œâ”€â”€ ğŸ“‚ go/
â”‚       â”œâ”€â”€ ğŸ“‚ left/
â”‚       â”œâ”€â”€ ğŸ“‚ no/
â”‚       â”œâ”€â”€ ğŸ“‚ right/
â”‚       â”œâ”€â”€ ğŸ“‚ stop/
â”‚       â”œâ”€â”€ ğŸ“‚ up/
â”‚       â””â”€â”€ ğŸ“‚ yes/
â”‚
â”œâ”€â”€ ğŸ“‚ processed_data/                    # Cached preprocessed data
    â”œâ”€â”€ preprocessed_data.npz
    â””â”€â”€ metadata.json

```

---

## ğŸ“Š Dataset

This project uses the **Mini Speech Commands** dataset from Google:

| Property | Value |
|----------|-------|
| **Source** | [TensorFlow Speech Commands](https://www.tensorflow.org/datasets/catalog/speech_commands) |
| **Samples** | 8,000 total (1,000 per class) |
| **Classes** | 8 speech commands |
| **Format** | WAV, 16-bit PCM |
| **Sample Rate** | 16,000 Hz |
| **Duration** | ~1 second per sample |

The dataset is automatically downloaded when you run the notebook.

---

## ğŸ”¬ Technical Details

### Preprocessing Pipeline

| Step | Description | Purpose |
|------|-------------|---------|
| **1. Duplicate Removal** | MD5 hash comparison | Remove redundant samples |
| **2. DC Offset Removal** | Subtract mean | Center signal at zero |
| **3. Length Normalization** | Pad/truncate to 16,000 samples | Ensure uniform length |
| **4. Pre-emphasis** | `y[n] = x[n] - 0.97Â·x[n-1]` | Boost high frequencies |
| **5. Amplitude Normalization** | Scale to [-1, 1] | Standardize amplitude range |

### Framing Parameters

| Parameter | Value | Samples |
|-----------|-------|---------|
| Frame Length | 25 ms | 400 |
| Hop Length | 10 ms | 160 |
| Overlap | 60% | 240 |
| Window | Hamming | â€” |
| Frames/Sample | 98 | â€” |

---

## ğŸ“ˆ Results

### Dataset Statistics After Preprocessing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PREPROCESSING RESULTS          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Original samples:     8,000           â”‚
â”‚  Duplicates removed:      27           â”‚
â”‚  Final samples:        7,973           â”‚
â”‚  Total frames:       781,354           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Samples per class:   ~996-998         â”‚
â”‚  Dataset balanced:    âœ… Yes           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technical Implementation Details

### Train / Test Split 
```python
X_train_frames, X_test_frames, y_train, y_test = train_test_split(
    frames_data, labels, test_size=0.20, random_state=42, stratify=labels
)


### FFT Feature Extraction 
X_train_spectrum = np.abs(np.fft.rfft(X_train_frames, axis=2)).astype(np.float32)
X_test_spectrum  = np.abs(np.fft.rfft(X_test_frames,  axis=2)).astype(np.float32)
# Output: (6378, 98, 201) â†’ 98 frames Ã— 201 frequency bins
```


## ğŸ› ï¸ Requirements

- Python 3.8+
- NumPy
- SciPy
- Matplotlib

See [`requirements.txt`](requirements.txt) for exact versions.

---

## ğŸ—ºï¸ Roadmap

- [x] **Stage 1:** Data Loading & Verification
- [x] **Stage 2:** Preprocessing & Framing
- [ ] **Stage 3:** Feature Extraction (MFCC, Energy, ZCR)
- [ ] **Stage 4:** Template Creation (Reference patterns)
- [ ] **Stage 5:** Distance Metrics (DTW, Euclidean)
- [ ] **Stage 6:** Classification & Evaluation
- [ ] **Stage 7:** Real-time Demo

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Yussof Waleed**
- GitHub: [@Yussof-waleed](https://github.com/Yussof-Waleed)
- University: Helwan University - Level 4 - DSP Course

---

